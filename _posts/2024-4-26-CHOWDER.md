---
layout: post
title: 多实例学习：CHOWDER
categories: [MIL, computational histopathology, weakly-supervised]
---


[**CLASSIFICATION AND DISEASE LOCALIZATION IN HISTOPATHOLOGY USING ONLY GLOBAL LABELS:A WEAKLY-SUPERVISED APPROACH**](https://arxiv.org/abs/1802.02212)
## 简介
这是一篇2020年的文章，由人工智能公司Owkin提出模型CHOWDER，属于比较早期计算病理学的文章。也属于[多实例学习multi-instance learning]()     

## 1 INTRODUCTION 

## 2 LEARNING WITHOUT LOCAL ANNOTATIONS

### 2.1病理图片预处理
#### Tissue Detection，Color Normalization
取得切片中的组织部分，并进行标准化，具体见原文，值得一提的是最近的文章显示一些复杂的病理切片标准化方法与简单的标准化并没有太大差异。具体可见kaggle的这个比赛[Owkin团队的方案](https://www.kaggle.com/competitions/UBC-OCEAN/discussion/466455)
#### Tiling
![alt text](/assets/image/2024-4-26-CHOWDER.md/image.png)

普遍方案是取20x放大，224 × 224px将每个slide切成不重叠的patch(tile)，本文也不例外。可以使用OpenSlide库完成。本文给出一个每个包采样数量的如下经验公式:
$$
M^{S}_{i, \ell} = \min_{i, \ell} \left( M^{T}_{i, \ell}, \max \left( M^{T}_{\text{min}}, 1 - \frac{1}{2} \bar M^{T}_{\ell} \right) \right)
$$
左侧是第$i$个样本采样数量，右侧$max$中的$\bar M^{T}_{\ell} = \frac{1}{N}\Sigma_iM_{i,\ell}^T$,也就是所有patch数量的均值（文章中说的是经验均值empirical average，什么意思？）

#### Feature extraction
提取每个patch的特征，使用ImageNet预训练的ResNet-50，平衡模型复杂度和模型效果

### 2.2 baseline method
略

### 2.3 CHOWDER method
![alt text](/assets/image/2024-4-26-CHOWDER.md/image-1.png)

在使用ResNet-50提取每个patch的特征（embedding）,数量为$dim_{embed} = 2048$,这样获得了一个$n_{tile} × 2048$的向量，接下来在$n_{tile}$轴上使用卷积核为2048的一维卷积（等价于fc）.文章中记卷积层数为$J$,并提到使用$J=1$的时候误差最小,选择$J>1$将减少训练误差，但会增加泛化误差。这样便获得了一个$n_{tile} × 1$的向量。
获得了这个向量后，通过<code>min-max layer</code>获得前R个和后R个数，在经过MLP获得分类结果。
本文解决MIL中实例数量不等的方法是使用<code>max-min layer</code>，也是比较常用的做法

## 3 EXPERIMENTAL RESULTS
最后的MLP分类层使用较大的dropout=0.5,本文训练$E$个CHOWDER模型,发现$E=50$效果较好，选择的min-max层使用$R=10$效果较好
![alt text](/assets/image/2024-4-26-CHOWDER.md/image-2.png)
Camelyon-16 (left) and TCGA-Lung (right)

## 4 Visualization
![alt text](/assets/image/2024-4-26-CHOWDER.md/image-3.png)